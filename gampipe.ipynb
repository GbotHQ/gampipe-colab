{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMpkK9Wk7caE"
      },
      "outputs": [],
      "source": [
        "#@title # GPU info { display-mode: \"form\" }\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1i18vwnk79s"
      },
      "source": [
        "# Stable Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS-NvNhk0KrS"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6oxn3iN5q_q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import path as osp\n",
        "\n",
        "upload_dir = \"upload\"\n",
        "results_dir = \"results\"\n",
        "\n",
        "os.makedirs(upload_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khoCNOCuHNd"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm ninja accelerate transformers ftfy\n",
        "!pip install -q diffusers==0.9.0\n",
        "!pip install -q gradio\n",
        "!pip install -q \"ipywidgets>=7,<8\"\n",
        "!pip install -q ftfy pathvalidate omegaconf\n",
        "\n",
        "!sudo apt update\n",
        "!wget --no-check-certificate https://mega.nz/linux/repo/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb\n",
        "!sudo apt install /content/megacmd-xUbuntu_18.04_amd64.deb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Vsv_1uzFqN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "from io import BytesIO\n",
        "from random import SystemRandom\n",
        "import gc\n",
        "\n",
        "import selectors\n",
        "import subprocess\n",
        "import sys\n",
        "import shlex\n",
        "\n",
        "import ast\n",
        "import re\n",
        "import itertools\n",
        "import json\n",
        "import pathlib\n",
        "from pathvalidate import sanitize_filename\n",
        "import shutil\n",
        "\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "from ipywidgets import widgets\n",
        "\n",
        "import google\n",
        "from google.colab import files\n",
        "from IPython import display\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from transformers import CLIPModel, CLIPTextModel, CLIPTokenizer, CLIPFeatureExtractor\n",
        "from diffusers import (\n",
        "    StableDiffusionPipeline,\n",
        "    StableDiffusionImg2ImgPipeline,\n",
        "    StableDiffusionInpaintPipeline,\n",
        ")\n",
        "from diffusers import DDIMScheduler, LMSDiscreteScheduler, DPMSolverMultistepScheduler, EulerDiscreteScheduler\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fBqheJi7rz7"
      },
      "outputs": [],
      "source": [
        "def bash(*args, param={}):\n",
        "    param['bufsize'] = 1\n",
        "    param['stdout'] = subprocess.PIPE\n",
        "    param['stderr'] = subprocess.PIPE\n",
        "    for command in args:\n",
        "        process = subprocess.Popen(shlex.split(command), **param)\n",
        "\n",
        "        sel = selectors.DefaultSelector()\n",
        "        sel.register(process.stdout, selectors.EVENT_READ)\n",
        "        sel.register(process.stderr, selectors.EVENT_READ)\n",
        "\n",
        "        while True:\n",
        "            for key, _ in sel.select():\n",
        "                data = key.fileobj.read1().decode()\n",
        "                if not data:\n",
        "                    break\n",
        "                if key.fileobj is process.stdout:\n",
        "                    print(data, end=\"\")\n",
        "                else:\n",
        "                    print(data, end=\"\", file=sys.stderr)\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "\n",
        "class mega_dl:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            subprocess.Popen(shlex.split('mega-help'))\n",
        "        except:\n",
        "            bash(\n",
        "                '''sudo apt update''',\n",
        "                '''wget --no-check-certificate https://mega.nz/linux/repo/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb''',\n",
        "                '''sudo apt install /content/megacmd-xUbuntu_18.04_amd64.deb'''\n",
        "            )\n",
        "    def dl(self, url, dir):\n",
        "        bash('mega-get {} {}'.format(url, dir))\n",
        "mega = mega_dl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym8giUojq2Mo"
      },
      "outputs": [],
      "source": [
        "rand = SystemRandom()\n",
        "\n",
        "model_path_clip = \"openai/clip-vit-large-patch14\"\n",
        "config_path = \"conf.json\"\n",
        "\n",
        "\n",
        "# Define layouts\n",
        "layouts = {\n",
        "    \"img_grid\": widgets.Layout(\n",
        "        grid_template_columns=\"repeat(3, 1fr)\",\n",
        "        display=\"inline-grid\",\n",
        "        gap=\"0px\",\n",
        "        padding=\"0px\",\n",
        "        margin=\"0px\",\n",
        "        align_content=\"flex-start\",\n",
        "    ),\n",
        "    \"img\": widgets.Layout(padding=\"0px\", margin=\"0px\", vertical_align=\"bottom\"),\n",
        "    \"output\": widgets.Layout(max_height=\"768px\", overflow=\"auto\")\n",
        "}\n",
        "\n",
        "\n",
        "def load_init_image(path):\n",
        "    \"\"\"Load init image and resize to fit 512\"\"\"\n",
        "\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    if img is None:\n",
        "        raise Exception(f\"Failed to load image from {path}.\")\n",
        "\n",
        "    # resize to fit 512\n",
        "    res = np.array(img.size, np.int32)\n",
        "\n",
        "    new_res = res * 512 // np.amin(res) // 8 * 8\n",
        "    res_mult = np.mean(new_res / res)\n",
        "\n",
        "    # use bicubic for downsampling and lanczos for upsampling\n",
        "    inter = Image.BICUBIC\n",
        "    if res_mult > 1:\n",
        "        inter = Image.LANCZOS\n",
        "    \n",
        "    img = img.resize(new_res, inter)\n",
        "\n",
        "    print(f\"{path}, resized to {new_res[0]}x{new_res[1]}\")\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) <= rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def download_byte_img(img_bytes, path, fmt):\n",
        "    \"\"\"Save bytes to image file and download\"\"\"\n",
        "    with open(path, \"wb\") as binary_file:\n",
        "        binary_file.write(img_bytes)\n",
        "    files.download(path)\n",
        "\n",
        "\n",
        "def pil_to_bytes(img, fmt):\n",
        "    \"\"\"Encode a PIL image to bytes\"\"\"\n",
        "    buff = BytesIO()\n",
        "    img.save(buff, format=fmt, compress_level=1)\n",
        "    return buff.getvalue()\n",
        "\n",
        "\n",
        "def get_printable_json_config(config):\n",
        "    \"\"\"Convert a json config to a printable version\"\"\"\n",
        "    string = \"\"\n",
        "    for line in config.splitlines()[1:-1]:\n",
        "        string += line.strip() + \"\\n\"\n",
        "    return string\n",
        "\n",
        "\n",
        "def defined_kwargs(**kwargs):\n",
        "    return {k: v for k, v in kwargs.items() if not v is None}\n",
        "\n",
        "\n",
        "def remove_keys(dictionary, keys):\n",
        "    dictionary = dictionary.copy()\n",
        "    for item in keys:\n",
        "        dictionary.pop(item)\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def rename_key(dictionary, old_name, new_name):\n",
        "    tmp = dictionary[old_name]\n",
        "    dictionary = remove_keys(dictionary, [old_name])\n",
        "    dictionary[new_name] = tmp\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def read_config(path):\n",
        "    \"\"\"Read config for generating\"\"\"\n",
        "    # Load the config from file\n",
        "    with open(config_path) as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Generate seed if used\n",
        "    if config[\"seed\"] < 0:\n",
        "        config[\"seed\"] = rand.randint(0, 2**14)\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def generate_label(prompt, config, seed, iter):\n",
        "    # Get label and filename\n",
        "    label = prompt[0][:200]\n",
        "    if len(prompt[0]) > 200:\n",
        "        label = label + \"... \"\n",
        "    if not prompt[1] is ():\n",
        "        label = f\"variation: <b>{str(list(prompt[1]))[1:-1]}</b>\"\n",
        "    else:\n",
        "        label = f\"prompt: <b>{label}</b>\"\n",
        "\n",
        "    label += f\"; seed: {seed}\"\n",
        "\n",
        "    if n_iter > 1:\n",
        "        label += f\"; iter: {iter + 1}\"\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def parse_prompt(prompt):\n",
        "    \"\"\"Parse lists in prompts to prompt variations\"\"\"\n",
        "\n",
        "    pattern = r\"\\[([^[\\]]*)\\]\"\n",
        "    matches = re.finditer(pattern, prompt)\n",
        "\n",
        "    groups = [m.group(0) for m in matches]\n",
        "\n",
        "    # get all possible combinations\n",
        "    combinations = list(itertools.product(*[ast.literal_eval(g) for g in groups]))\n",
        "\n",
        "    # create a prompt for each combination\n",
        "    new_prompts = []\n",
        "    for comb in combinations:\n",
        "        new_prompt = prompt\n",
        "        for group, word in zip(groups, comb):\n",
        "            new_prompt = new_prompt.replace(group, word)\n",
        "\n",
        "        new_prompts.append(new_prompt)\n",
        "\n",
        "    return list(zip(new_prompts, combinations))\n",
        "\n",
        "\n",
        "def tags_to_prompt(prompt, tags, excluded_tags, max_tags, tag_confidence_threshold):\n",
        "    def replace_underscores(string):\n",
        "        return string.replace(\"_\", \" \")\n",
        "\n",
        "    def accepted_substrings(string, accepted):\n",
        "        for substring in accepted:\n",
        "            if substring in string:\n",
        "                return False\n",
        "        \n",
        "        return True\n",
        "\n",
        "    def prep(string):\n",
        "        return replace_underscores(string).strip()\n",
        "\n",
        "    prompt = prep(prompt.replace(\"/\", \"\"))\n",
        "    excluded_tags = excluded_tags.split(\",\")\n",
        "    excluded_tags = [prep(t) for t in excluded_tags]\n",
        "\n",
        "\n",
        "    tags = []\n",
        "    for i, k in enumerate(preds):\n",
        "        if preds[k] < tag_confidence_threshold:\n",
        "            break\n",
        "        \n",
        "        k = prep(k)\n",
        "        \n",
        "        if not accepted_substrings(k, excluded_tags):\n",
        "            print(f\"Excluded {k}\")\n",
        "            continue\n",
        "        \n",
        "        tags.append(k)\n",
        "\n",
        "        if len(tags) == max_tags:\n",
        "            break\n",
        "    \n",
        "    autotagger_prompt = \", \".join(tags)\n",
        "\n",
        "    if not prompt is \"\":\n",
        "        autotagger_prompt = prompt + \", \" + autotagger_prompt\n",
        "\n",
        "    return autotagger_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Deepbooru:\n",
        "    def __init__(self):\n",
        "        self.interface = None\n",
        "    \n",
        "    def __call__(self, path):\n",
        "        if self.interface is None:\n",
        "            self.interface = gr.Interface.load(\"spaces/hysts/DeepDanbooru\")\n",
        "\n",
        "        out = self.interface(path, 0)\n",
        "\n",
        "        with open(out) as f:\n",
        "            preds = json.load(f)[\"confidences\"]\n",
        "        \n",
        "        return {x[\"label\"]: x[\"confidence\"] for x in preds}\n",
        "\n",
        "deepbooru = Deepbooru()"
      ],
      "metadata": {
        "id": "m-OyDdxXjNNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn8Gp6fjR0Ns"
      },
      "outputs": [],
      "source": [
        "from transformers.feature_extraction_utils import FeatureExtractionMixin\n",
        "\n",
        "class dummy_safety_checker:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def __call__(self, images, **kwargs):\n",
        "        return images, False\n",
        "\n",
        "class dummy_feature_extractor(FeatureExtractionMixin):   \n",
        "    def dummy(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.pixel_values = self\n",
        "        self.to = self.dummy\n",
        "        pass\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "\n",
        "class SD:\n",
        "    def __init__(\n",
        "        self,\n",
        "        device=\"cuda\",\n",
        "        torch_dtype=torch.float16,\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.torch_dtype = torch_dtype\n",
        "\n",
        "        self.revision = None\n",
        "        self.initialized = False\n",
        "        self.is_anime_autoencoder = None\n",
        "    \n",
        "\n",
        "    def __get_ctx(self):\n",
        "        return {\"device\": self.device, \"dtype\": self.torch_dtype}\n",
        "\n",
        "\n",
        "    def initialize_models(self):\n",
        "        if self.initialized:\n",
        "            return\n",
        "        \n",
        "        self.clip_tokenizer = CLIPTokenizer.from_pretrained(model_path_clip)\n",
        "        self.clip_model = CLIPTextModel.from_pretrained(model_path_clip, torch_dtype=self.torch_dtype)\n",
        "\n",
        "        self.initialized = True\n",
        "    \n",
        "\n",
        "    def init_vae(self, anime, **kwargs):\n",
        "        if self.is_anime_autoencoder == anime:\n",
        "            return\n",
        "\n",
        "        model_args = {\"torch_dtype\": self.torch_dtype}\n",
        "        if anime:\n",
        "            model_args[\"pretrained_model_name_or_path\"] = \"Linaqruf/anything-v3.0\"\n",
        "            model_args[\"subfolder\"] = \"vae\"\n",
        "        else:\n",
        "            model_args[\"pretrained_model_name_or_path\"] = \"stabilityai/sd-vae-ft-mse\"\n",
        "        \n",
        "        model_args.update(kwargs)\n",
        "\n",
        "        self.vae = AutoencoderKL.from_pretrained(**model_args)\n",
        "\n",
        "\n",
        "    def init_unet(self, model_path, **kwargs):\n",
        "        return UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", torch_dtype=self.torch_dtype, **kwargs).to(self.device)\n",
        "\n",
        "\n",
        "    def __init_composed_unet(self, unets, alphas, unet_kwargs_list):\n",
        "        def ensure_dict_format_validity(unet1, unet2):\n",
        "            if not unet_dict.keys() == base_unet_dict.keys():\n",
        "                raise Exception(\"Combined models must have the same architecture\")\n",
        "                \n",
        "            for key in base_unet_dict:\n",
        "                assert unet_dict[key].shape == base_unet_dict[key].shape\n",
        "        \n",
        "        n_unets = len(unets)\n",
        "\n",
        "        if unet_kwargs_list is None:\n",
        "            unet_kwargs_list = [{}] * n_unets\n",
        "        \n",
        "        assert n_unets == len(unet_kwargs_list)\n",
        "        assert n_unets == len(alphas)\n",
        "        \n",
        "        \n",
        "        base_unet = self.init_unet(unets[0], **unet_kwargs_list[0])\n",
        "        base_unet_dict = base_unet.state_dict()\n",
        "\n",
        "\n",
        "        # normalize alphas\n",
        "        alphas = torch.tensor(alphas, dtype=torch.float16)\n",
        "        alphas /= torch.sum(alphas)\n",
        "\n",
        "\n",
        "        for key in base_unet_dict:\n",
        "            base_unet_dict[key] *= alphas[0]\n",
        "\n",
        "\n",
        "        unets = unets[1:]\n",
        "        unet_kwargs_list = unet_kwargs_list[1:]\n",
        "        alphas = alphas[1:]\n",
        "\n",
        "\n",
        "        for i in range(n_unets - 1):\n",
        "            unet_dict = self.init_unet(unets[i], **unet_kwargs_list[i]).state_dict()\n",
        "\n",
        "            ensure_dict_format_validity(base_unet_dict, unet_dict)\n",
        "\n",
        "            for key in base_unet_dict:\n",
        "                base_unet_dict[key] += unet_dict[key] * alphas[i]\n",
        "\n",
        "\n",
        "            print(base_unet.load_state_dict(base_unet_dict))\n",
        "        \n",
        "        return base_unet\n",
        "\n",
        "    \n",
        "    def init_unets(\n",
        "        self, unets, alphas=None, unet_kwargs_list=None,\n",
        "    ):\n",
        "        n_unets = len(unets)\n",
        "        \n",
        "        if unet_kwargs_list is None:\n",
        "            unet_kwargs_list = [{}] * n_unets\n",
        "        if alphas is None:\n",
        "            alphas = [1] * n_unets\n",
        "        \n",
        "        assert n_unets == len(unet_kwargs_list)\n",
        "        \n",
        "        if n_unets == 1:\n",
        "            unet = self.init_unet(unets[0], **unet_kwargs_list[0])\n",
        "        else:            \n",
        "            unet = self.__init_composed_unet(unets, alphas, unet_kwargs_list)\n",
        "\n",
        "        # garbage collect\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        self.unet = unet\n",
        "\n",
        "\n",
        "    def to_device(self):\n",
        "        ctx = self.__get_ctx()\n",
        "\n",
        "        self.clip_model = self.clip_model.eval().to(**ctx)\n",
        "        self.vae = self.vae.eval().to(**ctx)\n",
        "        self.unet = self.unet.eval().to(**ctx)\n",
        "\n",
        "\n",
        "    def intitalize_scheduler(\n",
        "        self, type, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\"\n",
        "    ):\n",
        "        if type == \"ddim\":\n",
        "            return DDIMScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "                clip_sample=False,\n",
        "                set_alpha_to_one=False,\n",
        "            )\n",
        "\n",
        "        elif type == \"lms\":\n",
        "            return LMSDiscreteScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "            )\n",
        "        elif type == \"dpm\":\n",
        "            return DPMSolverMultistepScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "            )\n",
        "        elif type == \"euler\":\n",
        "            return EulerDiscreteScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "                prediction_type=\"v_prediction\",\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise Exception(f\"{type} is not a supported scheduler.\")\n",
        "    \n",
        "    \n",
        "    def generate(self, seed, **kwargs):\n",
        "        pipe_type = StableDiffusionPipeline\n",
        "        if kwargs[\"init_image\"]:\n",
        "            pipe_type = StableDiffusionImg2ImgPipeline\n",
        "        elif kwargs[\"mask_image\"]:\n",
        "            pipe_type = StableDiffusionInpaintPipeline\n",
        "\n",
        "        test_pipe = pipe_type(\n",
        "            vae=self.vae,\n",
        "            text_encoder=self.clip_model,\n",
        "            tokenizer=self.clip_tokenizer,\n",
        "            unet=self.unet,\n",
        "            scheduler=self.intitalize_scheduler(kwargs[\"scheduler_type\"]),\n",
        "            safety_checker=dummy_safety_checker(),\n",
        "            feature_extractor=dummy_feature_extractor()\n",
        "        ).to(self.device)\n",
        "\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "        return test_pipe(**kwargs, generator=generator).images\n",
        "\n",
        "\n",
        "GampipeSD = SD()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzDsfckh0QhC"
      },
      "source": [
        "## App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq7x4wy5Qw06"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate { display-mode: \"form\" }\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSKjRwalzh-K"
      },
      "outputs": [],
      "source": [
        "#@title Settings { display-mode: \"form\" }\n",
        "\n",
        "# @markdown ### Supported models:\n",
        "# @markdown <ul>\n",
        "# @markdown <li>sd: runwayml/stable-diffusion-v1-5</li>\n",
        "# @markdown <li>ad: Linaqruf/anything-v3.0</li>\n",
        "# @markdown <li>wd: hakurei/waifu-diffusion</li>\n",
        "# @markdown <li>nd: novelai-diffusion</li>\n",
        "# @markdown </ul>\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "models = {\n",
        "    \"sd\": \"runwayml/stable-diffusion-v1-5\",\n",
        "    \"ad\": \"Linaqruf/anything-v3.0\",\n",
        "    \"wd\": \"hakurei/waifu-diffusion\",\n",
        "    \"nd\": \"https://mega.nz/file/ThZi2CTJ#2Hu_glv74Q60-F-M_0AbWdCtfyL4bTZsoGfBZk9rjXk\",\n",
        "}\n",
        "\n",
        "model_names = \"ad wd\" #@param {type:\"string\"}\n",
        "merge_ratio = \"1 1\" #@param {type:\"string\"}\n",
        "\n",
        "anime_autoencoder = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "model_names = model_names.strip().split(\" \")\n",
        "merge_ratio = merge_ratio.strip().split(\" \")\n",
        "\n",
        "model_paths = [models[m] for m in model_names]\n",
        "\n",
        "if not merge_ratio[0] == \"\":\n",
        "    merge_ratio = [float(w) for w in merge_ratio]\n",
        "else:\n",
        "    merge_ratio = None\n",
        "\n",
        "\n",
        "unets = []\n",
        "unet_kwargs = []\n",
        "for model_name, model_path in zip(model_names, model_paths):\n",
        "    if model_path.startswith(\"https://mega.nz/\"):\n",
        "        archive_path = \"/content/animefull-final-pruned_unet.tar.gz\"\n",
        "        folder_path = \"/content/content/animefull-final-pruned\"\n",
        "\n",
        "        print(os.getcwd())\n",
        "\n",
        "        if not osp.isfile(archive_path):\n",
        "            bash(f\"mega-get {model_path} /content/\")\n",
        "        if not osp.isdir(folder_path):\n",
        "            archive = tarfile.open(archive_path)\n",
        "            archive.extractall(\"./\")\n",
        "\n",
        "            archive.close()\n",
        "        \n",
        "        unets.append(folder_path)\n",
        "    \n",
        "    else:        \n",
        "        unets.append(model_path)\n",
        "    \n",
        "    kwargs = {}\n",
        "\n",
        "    if model_name != \"ad\":\n",
        "        kwargs[\"revision\"] = \"fp16\"\n",
        "    \n",
        "    unet_kwargs.append(kwargs)\n",
        "\n",
        "\n",
        "GampipeSD.init_unets(unets, merge_ratio, unet_kwargs)\n",
        "GampipeSD.init_vae(anime_autoencoder)\n",
        "GampipeSD.initialize_models()\n",
        "GampipeSD.to_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypllz_Kjrk2m"
      },
      "outputs": [],
      "source": [
        "# @title # Settings { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ## General Settings\n",
        "config = {}\n",
        "\n",
        "prompt = \"\"  # @param {type:\"string\"}\n",
        "negative_prompt = \"poo quality, bad quality\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "aspect_ratio = \"vertical\" #@param [\"vertical\", \"horizontal\", \"square\"]\n",
        "guidance_scale = 12  # @param {type:\"slider\", min:-50, max:50, step:1}\n",
        "steps = 50  # @param {type:\"slider\", min:1, max:150, step:1}\n",
        "seed = 128  # @param {type:\"integer\"}\n",
        "# @markdown ***\n",
        "\n",
        "n_iter = 3  # @param {type:\"slider\", min:1, max:12, step:1}\n",
        "\n",
        "# @markdown ***\n",
        "# @markdown #### Danbooru autotagger\n",
        "use_auto_tagger = True #@param {type:\"boolean\"}\n",
        "image = \"test.jpg\"  # @param {type:\"string\"}\n",
        "max_tags = 16  # @param {type:\"slider\", min:1, max:50, step:1}\n",
        "confidence_thresh = 1  # @param {type:\"slider\", min:1, max:99, step:1}\n",
        "excluded_tags = \"censor, pubic, futa, penis\"  # @param {type:\"string\"}\n",
        "\n",
        "if use_auto_tagger:\n",
        "    deepbooru_image_path = osp.abspath(osp.join(upload_dir, image))\n",
        "    if not osp.isfile(deepbooru_image_path):\n",
        "        raise Exception(f\"Specified image for autotagger not found in {deepbooru_image_path}\")\n",
        "    \n",
        "    preds = deepbooru(deepbooru_image_path)\n",
        "    prompt = tags_to_prompt(prompt, preds, excluded_tags, max_tags, confidence_thresh / 100)\n",
        "\n",
        "# @markdown ***\n",
        "# @markdown ### img2img and inpainting settings\n",
        "\n",
        "\n",
        "use_init_image = False #@param {type:\"boolean\"}\n",
        "init_image = \"test.jpg\"  # @param {type:\"string\"}\n",
        "inpainting_mask_image = \"*_mask.jpg\"  # @param {type:\"string\"}\n",
        "init_image_strength = 45  # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "\n",
        "init_image_path = osp.join(upload_dir, init_image)\n",
        "mask_image_path = inpainting_mask_image.replace(\"*\", \"{}\")\n",
        "mask_image_path = mask_image_path.format(osp.splitext(init_image_path)[0])\n",
        "\n",
        "init_image = None\n",
        "mask_image = None\n",
        "if use_init_image:\n",
        "    if not osp.isfile(init_image_path):\n",
        "        raise Exception(f\"Specified init_image not found in {init_image_path}\")\n",
        "    \n",
        "    init_image = load_init_image(init_image_path)\n",
        "\n",
        "    if osp.isfile(mask_image_path):\n",
        "        mask_image = load_init_image(\n",
        "            osp.join(upload_dir, mask_image_path), init_image.size\n",
        "        )\n",
        "        display.display(image_grid([init_image, mask_image], 1, 2))\n",
        "\n",
        "    display.display(init_image)\n",
        "\n",
        "\n",
        "prompt = prompt.lower().strip()\n",
        "negative_prompt = negative_prompt.lower().strip()\n",
        "\n",
        "width = height = 512\n",
        "if aspect_ratio == \"vertical\":\n",
        "  height = 768\n",
        "elif aspect_ratio == \"horizontal\":\n",
        "  width = 768\n",
        "\n",
        "if not init_image is None:\n",
        "    width, height = init_image.size\n",
        "\n",
        "config[\"prompt\"] = prompt\n",
        "config[\"negative_prompt\"] = negative_prompt\n",
        "config[\"guidance_scale\"] = float(guidance_scale)\n",
        "config[\"init_image_strength\"] = float(1 - init_image_strength / 100)\n",
        "config[\"seed\"] = seed\n",
        "config[\"n_iter\"] = n_iter\n",
        "config[\"steps\"] = steps\n",
        "\n",
        "config[\"width\"] = width\n",
        "config[\"height\"] = height\n",
        "\n",
        "config_json = json.dumps(config, indent=2)\n",
        "\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(config_json)\n",
        "\n",
        "print(get_printable_json_config(config_json))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U54_fUllIVm"
      },
      "source": [
        "### Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLtK1O9KYqOw"
      },
      "outputs": [],
      "source": [
        "# @title Generate { display-mode: \"form\" }\n",
        "# Read config\n",
        "\n",
        "# set shortcuts required by cross attention control code\n",
        "# device = GampipeSD.device\n",
        "# dtype = GampipeSD.torch_dtype\n",
        "\n",
        "# clip_tokenizer = GampipeSD.clip_tokenizer\n",
        "# clip_model = GampipeSD.clip_model\n",
        "# clip = clip_model.text_model\n",
        "# unet = GampipeSD.unet\n",
        "# vae = GampipeSD.vae\n",
        "# scheduler = GampipeSD.scheduler\n",
        "\n",
        "\n",
        "config = read_config(config_path)\n",
        "printable_config = get_printable_json_config(json.dumps(config, indent=2))\n",
        "\n",
        "print_config = \"<p>\"\n",
        "for line in printable_config.splitlines():\n",
        "    print_config += line + \"<br>\"\n",
        "print_config += \"</p>\"\n",
        "\n",
        "config_widget = widgets.HTML(\n",
        "    value=print_config,\n",
        "    placeholder=\"Config\",\n",
        ")\n",
        "\n",
        "\n",
        "# Get prompt variations\n",
        "prompts = parse_prompt(config[\"prompt\"])\n",
        "\n",
        "\n",
        "# Create outputs widgets to control order of outputs\n",
        "out = widgets.Output(layout=layouts[\"output\"])\n",
        "out1 = widgets.Output(layout=layouts[\"output\"])\n",
        "out2 = widgets.Output(layout=layouts[\"output\"])\n",
        "app = widgets.VBox([out, out1, out2])\n",
        "display.display(app)\n",
        "\n",
        "gb = widgets.GridBox([], layout=layouts[\"img_grid\"])\n",
        "with app.children[0]:\n",
        "    display.display(config_widget)\n",
        "\n",
        "with app.children[1]:\n",
        "    display.display(gb)\n",
        "\n",
        "# # Include button icons\n",
        "# with app.children[2]:\n",
        "#     display.display(\n",
        "#         display.HTML(\n",
        "#             \"\"\"<link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"> \"\"\"\n",
        "#         )\n",
        "#     )\n",
        "\n",
        "\n",
        "# Generate\n",
        "images = []\n",
        "i = 0\n",
        "for prompt in prompts:\n",
        "    for iter in range(config[\"n_iter\"]):\n",
        "        # set seed\n",
        "        seed = config[\"seed\"] + iter\n",
        "\n",
        "        with app.children[2]:\n",
        "            img = GampipeSD.generate(\n",
        "                seed=seed,\n",
        "                prompt=prompt[0],\n",
        "                negative_prompt=config[\"negative_prompt\"],\n",
        "                guidance_scale=config[\"guidance_scale\"],\n",
        "                strength=config[\"init_image_strength\"],\n",
        "                init_image=init_image,\n",
        "                mask_image=mask_image,\n",
        "                width=config[\"width\"],\n",
        "                height=config[\"height\"],\n",
        "                num_inference_steps=config[\"steps\"],\n",
        "                scheduler_type=\"dpm\",\n",
        "            )[0]\n",
        "\n",
        "        compressed = pil_to_bytes(img, \"png\")\n",
        "        images.append(compressed)\n",
        "\n",
        "        label = generate_label(prompt, config, seed, iter)\n",
        "\n",
        "        # Create widgets\n",
        "        info = widgets.HBox(\n",
        "            [\n",
        "                widgets.HTML(\n",
        "                    value=label,\n",
        "                    placeholder=\"Label\",\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        image_widget = widgets.VBox(\n",
        "            [info, widgets.Image(value=compressed, layout=layouts[\"img\"])]\n",
        "        )\n",
        "\n",
        "        gb.children = (*gb.children, image_widget)\n",
        "\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3RKjTO1jo_R"
      },
      "source": [
        "# SwinIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pXogAPUkwj_"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF4Pob_vjv0I"
      },
      "outputs": [],
      "source": [
        "!rm -r SwinIR\n",
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o0KuEmLj2oC"
      },
      "outputs": [],
      "source": [
        "def is_img(fn):\n",
        "    ext = [\"png\", \"jpg\", \"jpeg\"]\n",
        "\n",
        "    for ext in ext:\n",
        "        if fn.endswith(f\".{ext}\"):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def get_images(path):\n",
        "    files = os.listdir(path)\n",
        "\n",
        "    for f in files:\n",
        "        if not is_img(f):\n",
        "            files.remove(f)\n",
        "    return files\n",
        "\n",
        "\n",
        "def replace_ext(fn, ext):\n",
        "    return f\"{osp.splitext(fn)[0]}.{ext}\"\n",
        "\n",
        "\n",
        "def force_make_dir(path):\n",
        "    if osp.isdir(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGcOGF91j4qw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import path as osp\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "result_root = \"results\"\n",
        "upload = \"SwinIR Upload\"\n",
        "swin_result = osp.join(result_root, \"swinir_real_sr_x4_large\")\n",
        "\n",
        "for path in [result_root, upload, swin_result]:\n",
        "    force_make_dir(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lBB2TX4k2X2"
      },
      "source": [
        "## App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8FZUnTLlIVs"
      },
      "source": [
        "### Upscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QP7kQkSCkBT8"
      },
      "outputs": [],
      "source": [
        "#@title Upscale\n",
        "tiled = True #@param {type:\"boolean\"}\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "!rm -r $swin_result/*\n",
        "\n",
        "# SwinIR-Large\n",
        "if tiled:\n",
        "  !python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq \"$upload\" --scale 4 --large_model --tile 256\n",
        "else:\n",
        "  !python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq \"$upload\" --scale 4 --large_model\n",
        "shutil.rmtree('results/SwinIR_large', ignore_errors=True)\n",
        "shutil.move('results/swinir_real_sr_x4_large', 'results/SwinIR_large')\n",
        "for path in sorted(glob.glob(os.path.join('results/SwinIR_large', '*.png'))):\n",
        "  img = cv.imread(path)\n",
        "  cv.imwrite(path, img, [cv.IMWRITE_PNG_COMPRESSION, 9])\n",
        "  # os.rename(path, path.replace('SwinIR.png', 'SwinIR_large.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uS-NvNhk0KrS",
        "Z3RKjTO1jo_R",
        "2pXogAPUkwj_"
      ],
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('env_mfct')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8a0b49fd0c4635c91c882b7e82e49057ce426a150a19cf02f92541aeeca7358"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}