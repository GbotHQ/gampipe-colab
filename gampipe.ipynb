{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMpkK9Wk7caE"
      },
      "outputs": [],
      "source": [
        "#@title # GPU info { display-mode: \"form\" }\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1i18vwnk79s"
      },
      "source": [
        "# Stable Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS-NvNhk0KrS"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6oxn3iN5q_q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import path as osp\n",
        "from pathlib import Path as pth\n",
        "from pathlib import PurePath as ppth\n",
        "\n",
        "upload_root = pth(\"upload\")\n",
        "results_dir = pth(\"results\")\n",
        "download = pth(\"download\")\n",
        "converted = pth(\"converted\")\n",
        "\n",
        "deepbooru_image_dir = upload_root / \"deepbooru_image\"\n",
        "init_image_dir = upload_root / \"init_image\"\n",
        "mask_image_dir = upload_root / \"mask_image\"\n",
        "\n",
        "for path in [upload_root, results_dir, deepbooru_image_dir, init_image_dir, mask_image_dir, download, converted]:\n",
        "    path.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khoCNOCuHNd"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm ninja accelerate transformers ftfy safetensors\n",
        "!pip install -q diffusers==0.10.2\n",
        "!pip install -q gradio\n",
        "!pip install -q \"ipywidgets>=7,<8\"\n",
        "!pip install -q ftfy pathvalidate omegaconf\n",
        "\n",
        "!sudo apt update\n",
        "!wget --no-check-certificate https://mega.nz/linux/repo/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb\n",
        "!wget -nc \"https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\"\n",
        "!sudo apt install /content/megacmd-xUbuntu_18.04_amd64.deb\n",
        "!sudo apt install aria2 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Vsv_1uzFqN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "from io import BytesIO\n",
        "from random import SystemRandom\n",
        "import gc\n",
        "\n",
        "import selectors\n",
        "import subprocess\n",
        "import sys\n",
        "import shlex\n",
        "\n",
        "import ast\n",
        "import re\n",
        "import itertools\n",
        "import json\n",
        "import pathlib\n",
        "from pathvalidate import sanitize_filename\n",
        "import shutil\n",
        "\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "from ipywidgets import widgets\n",
        "\n",
        "import google\n",
        "from google.colab import files\n",
        "from IPython import display\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from transformers import CLIPModel, CLIPTextModel, CLIPTokenizer, CLIPFeatureExtractor\n",
        "from diffusers import (\n",
        "    StableDiffusionPipeline,\n",
        "    StableDiffusionImg2ImgPipeline,\n",
        "    StableDiffusionInpaintPipeline,\n",
        ")\n",
        "from diffusers import DDIMScheduler, LMSDiscreteScheduler, DPMSolverMultistepScheduler, EulerDiscreteScheduler\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fBqheJi7rz7"
      },
      "outputs": [],
      "source": [
        "def bash(*args, param={}):\n",
        "    param['bufsize'] = 1\n",
        "    param['stdout'] = subprocess.PIPE\n",
        "    param['stderr'] = subprocess.PIPE\n",
        "    for command in args:\n",
        "        process = subprocess.Popen(shlex.split(command), **param)\n",
        "\n",
        "        sel = selectors.DefaultSelector()\n",
        "        sel.register(process.stdout, selectors.EVENT_READ)\n",
        "        sel.register(process.stderr, selectors.EVENT_READ)\n",
        "\n",
        "        while True:\n",
        "            for key, _ in sel.select():\n",
        "                data = key.fileobj.read1().decode()\n",
        "                if not data:\n",
        "                    break\n",
        "                if key.fileobj is process.stdout:\n",
        "                    print(data, end=\"\")\n",
        "                else:\n",
        "                    print(data, end=\"\", file=sys.stderr)\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "\n",
        "class mega_dl:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            subprocess.Popen(shlex.split('mega-help'))\n",
        "        except:\n",
        "            bash(\n",
        "                '''sudo apt update''',\n",
        "                '''wget --no-check-certificate https://mega.nz/linux/repo/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb''',\n",
        "                '''sudo apt install /content/megacmd-xUbuntu_18.04_amd64.deb'''\n",
        "            )\n",
        "    def dl(self, url, dir):\n",
        "        bash('mega-get {} {}'.format(url, dir))\n",
        "mega = mega_dl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym8giUojq2Mo"
      },
      "outputs": [],
      "source": [
        "rand = SystemRandom()\n",
        "\n",
        "model_path_clip = pth(\"openai/clip-vit-large-patch14\")\n",
        "config_path = pth(\"conf.json\")\n",
        "\n",
        "\n",
        "# Define layouts\n",
        "layouts = {\n",
        "    \"img_grid\": widgets.Layout(\n",
        "        grid_template_columns=\"repeat(3, 1fr)\",\n",
        "        display=\"inline-grid\",\n",
        "        gap=\"0px\",\n",
        "        padding=\"0px\",\n",
        "        margin=\"0px\",\n",
        "        align_content=\"flex-start\",\n",
        "    ),\n",
        "    \"img\": widgets.Layout(padding=\"0px\", margin=\"0px\", vertical_align=\"bottom\"),\n",
        "    \"output\": widgets.Layout(max_height=\"768px\", overflow=\"auto\")\n",
        "}\n",
        "\n",
        "\n",
        "def clear_dir(dir):\n",
        "    if dir.is_dir():\n",
        "        shutil.rmtree(dir)\n",
        "    dir.mkdir()\n",
        "\n",
        "\n",
        "def load_init_image(path):\n",
        "    \"\"\"Load init image and resize to fit 512\"\"\"\n",
        "    img = Image.open(str(path)).convert(\"RGB\")\n",
        "\n",
        "    if img is None:\n",
        "        raise Exception(f\"Failed to load image from {path}.\")\n",
        "\n",
        "    # resize to fit 512\n",
        "    res = np.array(img.size, np.int32)\n",
        "\n",
        "    new_res = res * 512 // np.amin(res) // 8 * 8\n",
        "    res_mult = np.mean(new_res / res)\n",
        "\n",
        "    # use bicubic for downsampling and lanczos for upsampling\n",
        "    inter = Image.BICUBIC\n",
        "    if res_mult > 1:\n",
        "        inter = Image.LANCZOS\n",
        "    \n",
        "    img = img.resize(new_res, inter)\n",
        "\n",
        "    print(f\"{path}, resized to {new_res[0]}x{new_res[1]}\")\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) <= rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def download_byte_img(img_bytes, path, fmt):\n",
        "    \"\"\"Save bytes to image file and download\"\"\"\n",
        "    with open(str(path), \"wb\") as binary_file:\n",
        "        binary_file.write(img_bytes)\n",
        "    files.download(str(path))\n",
        "\n",
        "\n",
        "def pil_to_bytes(img, fmt):\n",
        "    \"\"\"Encode a PIL image to bytes\"\"\"\n",
        "    buff = BytesIO()\n",
        "    img.save(buff, format=fmt, compress_level=1)\n",
        "    return buff.getvalue()\n",
        "\n",
        "\n",
        "def get_printable_json_config(config):\n",
        "    \"\"\"Convert a json config to a printable version\"\"\"\n",
        "    string = \"\"\n",
        "    for line in config.splitlines()[1:-1]:\n",
        "        string += line.strip() + \"\\n\"\n",
        "    return string\n",
        "\n",
        "\n",
        "def defined_kwargs(**kwargs):\n",
        "    return {k: v for k, v in kwargs.items() if not v is None}\n",
        "\n",
        "\n",
        "def remove_keys(dictionary, keys):\n",
        "    dictionary = dictionary.copy()\n",
        "    for item in keys:\n",
        "        dictionary.pop(item)\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def rename_key(dictionary, old_name, new_name):\n",
        "    tmp = dictionary[old_name]\n",
        "    dictionary = remove_keys(dictionary, [old_name])\n",
        "    dictionary[new_name] = tmp\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def read_config():\n",
        "    \"\"\"Read config for generating\"\"\"\n",
        "    # Load the config from file\n",
        "    with open(str(config_path)) as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Generate seed if used\n",
        "    if config[\"seed\"] < 0:\n",
        "        config[\"seed\"] = rand.randint(0, 2**14)\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def generate_label(prompt, config, seed, iter):\n",
        "    # Get label and filename\n",
        "    label = prompt[0][:200]\n",
        "    if len(prompt[0]) > 200:\n",
        "        label = label + \"... \"\n",
        "    if prompt[1] != ():\n",
        "        label = f\"variation: <b>{str(list(prompt[1]))[1:-1]}</b>\"\n",
        "    else:\n",
        "        label = f\"prompt: <b>{label}</b>\"\n",
        "\n",
        "    label += f\"; seed: {seed}\"\n",
        "\n",
        "    if config[\"n_iter\"] > 1:\n",
        "        label += f\"; iter: {iter + 1}\"\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def parse_prompt(prompt):\n",
        "    \"\"\"Parse lists in prompts to prompt variations\"\"\"\n",
        "\n",
        "    pattern = r\"\\[([^[\\]]*)\\]\"\n",
        "    matches = re.finditer(pattern, prompt)\n",
        "\n",
        "    groups = [m.group(0) for m in matches]\n",
        "\n",
        "    # get all possible combinations\n",
        "    combinations = list(itertools.product(*[ast.literal_eval(g) for g in groups]))\n",
        "\n",
        "    # create a prompt for each combination\n",
        "    new_prompts = []\n",
        "    for comb in combinations:\n",
        "        new_prompt = prompt\n",
        "        for group, word in zip(groups, comb):\n",
        "            new_prompt = new_prompt.replace(group, word)\n",
        "\n",
        "        new_prompts.append(new_prompt)\n",
        "\n",
        "    return list(zip(new_prompts, combinations))\n",
        "\n",
        "\n",
        "def tags_to_prompt(prompt, tags, excluded_tags, max_tags, tag_confidence_threshold):\n",
        "    def replace_underscores(string):\n",
        "        return string.replace(\"_\", \" \")\n",
        "\n",
        "    def accepted_substrings(string, accepted):\n",
        "        for substring in accepted:\n",
        "            if substring in string:\n",
        "                return False\n",
        "        \n",
        "        return True\n",
        "\n",
        "    def prep(string):\n",
        "        return replace_underscores(string).strip()\n",
        "\n",
        "    prompt = prep(prompt.replace(\"/\", \"\"))\n",
        "    excluded_tags = excluded_tags.split(\",\")\n",
        "    excluded_tags = [prep(t) for t in excluded_tags]\n",
        "\n",
        "\n",
        "    tags = []\n",
        "    for i, k in enumerate(preds):\n",
        "        if preds[k] < tag_confidence_threshold:\n",
        "            break\n",
        "        \n",
        "        k = prep(k)\n",
        "        \n",
        "        if not accepted_substrings(k, excluded_tags):\n",
        "            print(f\"Excluded {k}\")\n",
        "            continue\n",
        "        \n",
        "        tags.append(k)\n",
        "\n",
        "        if len(tags) == max_tags:\n",
        "            break\n",
        "    \n",
        "    autotagger_prompt = \", \".join(tags)\n",
        "\n",
        "    if prompt != \"\":\n",
        "        autotagger_prompt = prompt + \", \" + autotagger_prompt\n",
        "\n",
        "    return autotagger_prompt\n",
        "\n",
        "\n",
        "def upload_img(target_path):\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # clear upload directory\n",
        "    shutil.rmtree(target_path)\n",
        "    target_path.mkdir()\n",
        "\n",
        "    uploaded_path = pth(list(uploaded.keys())[0])\n",
        "\n",
        "    new_uploaded_path = target_path / uploaded_path.name\n",
        "    uploaded_path.rename(new_uploaded_path)\n",
        "\n",
        "    assert new_uploaded_path.is_file()\n",
        "\n",
        "    return new_uploaded_path\n",
        "\n",
        "\n",
        "def convert_to_diffusers(model_path, out_path):\n",
        "    bash(f\"python convert_original_stable_diffusion_to_diffusers.py --checkpoint_path {model_path} --dump_path {out_path} --scheduler_type 'dpm' --device 'cuda'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Deepbooru:\n",
        "    def __init__(self):\n",
        "        self.interface = None\n",
        "    \n",
        "    def __call__(self, path):\n",
        "        if self.interface is None:\n",
        "            self.interface = gr.Interface.load(\"spaces/hysts/DeepDanbooru\")\n",
        "\n",
        "        out = self.interface(path, 0)\n",
        "\n",
        "        with open(out) as f:\n",
        "            preds = json.load(f)[\"confidences\"]\n",
        "        \n",
        "        return {x[\"label\"]: x[\"confidence\"] for x in preds}\n",
        "\n",
        "deepbooru = Deepbooru()"
      ],
      "metadata": {
        "id": "m-OyDdxXjNNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn8Gp6fjR0Ns"
      },
      "outputs": [],
      "source": [
        "from transformers.feature_extraction_utils import FeatureExtractionMixin\n",
        "\n",
        "class dummy_safety_checker:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def __call__(self, images, **kwargs):\n",
        "        return images, False\n",
        "\n",
        "class dummy_feature_extractor(FeatureExtractionMixin):   \n",
        "    def dummy(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.pixel_values = self\n",
        "        self.to = self.dummy\n",
        "        pass\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "\n",
        "class SD:\n",
        "    def __init__(\n",
        "        self,\n",
        "        device=\"cuda\",\n",
        "        torch_dtype=torch.float16,\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.torch_dtype = torch_dtype\n",
        "\n",
        "        self.revision = None\n",
        "\n",
        "\n",
        "    def __get_ctx(self):\n",
        "        return {\"device\": self.device, \"dtype\": self.torch_dtype}\n",
        "\n",
        "\n",
        "    def init_tokenizer(self, path=str(model_path_clip), **kwargs):        \n",
        "        self.clip_tokenizer = CLIPTokenizer.from_pretrained(path, **kwargs)\n",
        "\n",
        "\n",
        "    def init_encoder(self, path=str(model_path_clip), **kwargs):\n",
        "        self.clip_model = CLIPTextModel.from_pretrained(path, **kwargs)\n",
        "    \n",
        "\n",
        "    def init_vae(self, path, subfolder=\"vae\", **kwargs):\n",
        "        model_args = {}\n",
        "        model_args[\"torch_dtype\"] = self.torch_dtype\n",
        "        model_args[\"pretrained_model_name_or_path\"] = path\n",
        "        if subfolder:\n",
        "            model_args[\"subfolder\"] = subfolder\n",
        "\n",
        "        model_args.update(kwargs)\n",
        "\n",
        "        self.vae = AutoencoderKL.from_pretrained(**model_args)\n",
        "\n",
        "\n",
        "    def init_unet(self, model_path, **kwargs):\n",
        "        print(kwargs)\n",
        "        return UNet2DConditionModel.from_pretrained(model_path, subfolder=\"unet\", torch_dtype=self.torch_dtype, **kwargs).to(self.device)\n",
        "\n",
        "\n",
        "    def __init_composed_unet(self, unets, alphas, unet_kwargs_list):\n",
        "        def ensure_dict_format_validity(unet1, unet2):\n",
        "            if not unet_dict.keys() == base_unet_dict.keys():\n",
        "                raise Exception(\"Combined models must have the same architecture\")\n",
        "                \n",
        "            for key in base_unet_dict:\n",
        "                assert unet_dict[key].shape == base_unet_dict[key].shape\n",
        "        \n",
        "        n_unets = len(unets)\n",
        "\n",
        "        if unet_kwargs_list is None:\n",
        "            unet_kwargs_list = [{}] * n_unets\n",
        "        \n",
        "        assert n_unets == len(unet_kwargs_list)\n",
        "        assert n_unets == len(alphas)\n",
        "        \n",
        "        \n",
        "        base_unet = self.init_unet(unets[0], **unet_kwargs_list[0])\n",
        "        base_unet_dict = base_unet.state_dict()\n",
        "\n",
        "\n",
        "        # normalize alphas\n",
        "        alphas = torch.tensor(alphas, dtype=torch.float16)\n",
        "        alphas /= torch.sum(alphas)\n",
        "\n",
        "\n",
        "        for key in base_unet_dict:\n",
        "            base_unet_dict[key] *= alphas[0]\n",
        "\n",
        "\n",
        "        unets = unets[1:]\n",
        "        unet_kwargs_list = unet_kwargs_list[1:]\n",
        "        alphas = alphas[1:]\n",
        "\n",
        "\n",
        "        for i in range(n_unets - 1):\n",
        "            unet_dict = self.init_unet(unets[i], **unet_kwargs_list[i]).state_dict()\n",
        "\n",
        "            ensure_dict_format_validity(base_unet_dict, unet_dict)\n",
        "\n",
        "            for key in base_unet_dict:\n",
        "                base_unet_dict[key] += unet_dict[key] * alphas[i]\n",
        "\n",
        "\n",
        "            print(base_unet.load_state_dict(base_unet_dict))\n",
        "        \n",
        "        return base_unet\n",
        "\n",
        "    \n",
        "    def init_unets(\n",
        "        self, unets, alphas=None, unet_kwargs_list=None,\n",
        "    ):\n",
        "        n_unets = len(unets)\n",
        "        \n",
        "        if unet_kwargs_list is None:\n",
        "            unet_kwargs_list = [{}] * n_unets\n",
        "        if alphas is None:\n",
        "            alphas = [1] * n_unets\n",
        "        \n",
        "        assert n_unets == len(unet_kwargs_list)\n",
        "        \n",
        "        if n_unets == 1:\n",
        "            unet = self.init_unet(unets[0], **unet_kwargs_list[0])\n",
        "        else:            \n",
        "            unet = self.__init_composed_unet(unets, alphas, unet_kwargs_list)\n",
        "\n",
        "        # garbage collect\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        self.unet = unet\n",
        "\n",
        "\n",
        "    def to_device(self):\n",
        "        ctx = self.__get_ctx()\n",
        "\n",
        "        self.clip_model = self.clip_model.eval().to(**ctx)\n",
        "        self.vae = self.vae.eval().to(**ctx)\n",
        "        self.unet = self.unet.eval().to(**ctx)\n",
        "\n",
        "\n",
        "    def intitalize_scheduler(\n",
        "        self, type, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\"\n",
        "    ):\n",
        "        if type == \"ddim\":\n",
        "            return DDIMScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "                clip_sample=False,\n",
        "                set_alpha_to_one=False,\n",
        "            )\n",
        "\n",
        "        elif type == \"lms\":\n",
        "            return LMSDiscreteScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "            )\n",
        "        elif type == \"dpm\":\n",
        "            return DPMSolverMultistepScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "            )\n",
        "        elif type == \"euler\":\n",
        "            return EulerDiscreteScheduler(\n",
        "                beta_start=beta_start,\n",
        "                beta_end=beta_end,\n",
        "                beta_schedule=beta_schedule,\n",
        "                prediction_type=\"v_prediction\",\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise Exception(f\"{type} is not a supported scheduler.\")\n",
        "    \n",
        "    \n",
        "    def generate(self, seed, scheduler_type, **kwargs):\n",
        "        pipe_type = StableDiffusionPipeline\n",
        "        if kwargs[\"image\"]:\n",
        "            pipe_type = StableDiffusionImg2ImgPipeline\n",
        "        elif kwargs[\"mask_image\"]:\n",
        "            pipe_type = StableDiffusionInpaintPipeline\n",
        "\n",
        "        test_pipe = pipe_type(\n",
        "            vae=self.vae,\n",
        "            text_encoder=self.clip_model,\n",
        "            tokenizer=self.clip_tokenizer,\n",
        "            unet=self.unet,\n",
        "            scheduler=self.intitalize_scheduler(scheduler_type),\n",
        "            safety_checker=dummy_safety_checker(),\n",
        "            feature_extractor=dummy_feature_extractor()\n",
        "        ).to(self.device)\n",
        "\n",
        "        kwargs = {k: j for k, j in kwargs.items() if j is not None}\n",
        "\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "        return test_pipe(**kwargs, generator=generator).images\n",
        "\n",
        "\n",
        "GampipeSD = SD()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzDsfckh0QhC"
      },
      "source": [
        "## App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq7x4wy5Qw06"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate { display-mode: \"form\" }\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSKjRwalzh-K"
      },
      "outputs": [],
      "source": [
        "#@title ### Settings { display-mode: \"form\" }\n",
        "\n",
        "# @markdown ### Supported models:\n",
        "# @markdown <ul>\n",
        "# @markdown <li>sd: runwayml/stable-diffusion-v1-5</li>\n",
        "# @markdown <li>ad: Linaqruf/anything-v3.0</li>\n",
        "# @markdown <li>wd: hakurei/waifu-diffusion</li>\n",
        "# @markdown <li>nd: novelai-diffusion</li>\n",
        "# @markdown <li>mse: stabilityai/sd-vae-ft-mse</li>\n",
        "# @markdown <li>custom_model1: custom_model1</li>\n",
        "# @markdown <li>custom_model2: custom_model2</li>\n",
        "# @markdown </ul>\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "unet_model_names = \"custom_model2\" #@param {type:\"string\"}\n",
        "unet_merge_ratio = \"1 1\" #@param {type:\"string\"}\n",
        "vae_model_name = \"ad\" #@param {type:\"string\"}\n",
        "tokenizer_model_name = \"ad\" #@param {type:\"string\"}\n",
        "encoder_model_name = \"custom_model2\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "custom_model1 = \"eimiss/EimisAnimeDiffusion_1.0v\" #@param {type:\"string\"}\n",
        "custom_model1_branch = \"main\" #@param [\"main\", \"fp16\"]\n",
        "custom_model2 = \"magnet:?xt=urn:btih:969cabc39c8363aeec824f5530bb0749b6452621&dn=dreambooth-calli-nsfw&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2fopen.stealth.si%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.pomf.se%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce\" #@param {type:\"string\"}\n",
        "custom_model2_branch = \"main\" #@param [\"main\", \"fp16\"]\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "\n",
        "models = [\n",
        "    {\"name\": \"sd\", \"path\": \"runwayml/stable-diffusion-v1-5\", \"branch\": \"main\"},\n",
        "    {\"name\": \"ad\", \"path\": \"Linaqruf/anything-v3.0\", \"branch\": \"main\"},\n",
        "    {\"name\": \"wd\", \"path\": \"hakurei/waifu-diffusion\", \"branch\": \"main\"},\n",
        "    {\"name\": \"nd\", \"path\": \"https://mega.nz/file/ThZi2CTJ#2Hu_glv74Q60-F-M_0AbWdCtfyL4bTZsoGfBZk9rjXk\", \"branch\": None},\n",
        "    {\"name\": \"mse\", \"path\": \"stabilityai/sd-vae-ft-mse\", \"branch\": \"main\"},\n",
        "    {\"name\": \"custom_model1\", \"path\": custom_model1, \"branch\": custom_model1_branch},\n",
        "    {\"name\": \"custom_model2\", \"path\": custom_model2, \"branch\": custom_model2_branch}\n",
        "]\n",
        "\n",
        "\n",
        "def string_to_list(string):\n",
        "    return string.strip().split(\" \")\n",
        "\n",
        "def __get_model_params(model_name):\n",
        "    for k in models:\n",
        "        if k[\"name\"] == model_name:\n",
        "            return k\n",
        "\n",
        "def get_model_params(model_names):\n",
        "    return [__get_model_params(k) for k in model_names]\n",
        "\n",
        "\n",
        "unet_model_names = string_to_list(unet_model_names)\n",
        "if (unet_merge_ratio := string_to_list(unet_merge_ratio))[0] == \"\":\n",
        "    unet_merge_ratio = None\n",
        "else:\n",
        "    unet_merge_ratio = [float(w) for w in unet_merge_ratio]\n",
        "\n",
        "\n",
        "model_names = unet_model_names + [vae_model_name, tokenizer_model_name, encoder_model_name]\n",
        "model_names = list(set(model_names))\n",
        "\n",
        "n_magnet_models_used = 0\n",
        "all_models = []\n",
        "for k in get_model_params(model_names):\n",
        "    model = k.copy()\n",
        "\n",
        "    if k[\"path\"].startswith(\"https://mega.nz/\"):\n",
        "        clear_dir(download)\n",
        "        archive_path = pth(download, \"animefull-final-pruned_unet.tar.gz\")\n",
        "        folder_path = pth(download, \"animefull-final-pruned\")\n",
        "\n",
        "        print(os.getcwd())\n",
        "\n",
        "        if not archive_path.is_file():\n",
        "            bash(f\"mega-get {k['path']} {str(download)}\")\n",
        "        \n",
        "        if not folder_path.is_file():\n",
        "            archive = tarfile.open(str(archive_path))\n",
        "            archive.extractall(\"./\")\n",
        "\n",
        "            archive.close()\n",
        "        \n",
        "        model[\"path\"] = {\n",
        "            \"unet\": str(folder_path),\n",
        "            \"vae\": str(folder_path),\n",
        "            \"tokenizer\": str(folder_path),\n",
        "            \"encoder\": str(folder_path),\n",
        "        }\n",
        "\n",
        "    elif k[\"path\"].startswith(\"magnet:\"):\n",
        "        if n_magnet_models_used > 1:\n",
        "            raise Exception(\"Only one magnet model can be used at a time\")\n",
        "\n",
        "        clear_dir(download)\n",
        "        clear_dir(converted)\n",
        "\n",
        "        bash(f\"aria2c -d {str(download)} --seed-time=0 {k['path']}\")\n",
        "\n",
        "        model_paths = sorted(download.rglob(\"*.ckpt\"))\n",
        "        model_path = model_paths[0]\n",
        "        if len(model_paths) > 1:\n",
        "            print(f\"Warning: found multiple models {model_paths}, using {model_path}\")\n",
        "\n",
        "        convert_to_diffusers(model_path, str(converted))\n",
        "\n",
        "        model[\"path\"] = {\n",
        "            \"unet\": str(converted / \"unet\"),\n",
        "            \"vae\": str(converted / \"vae\"),\n",
        "            \"tokenizer\": str(converted),\n",
        "            \"encoder\": str(converted),\n",
        "        }\n",
        "\n",
        "        n_magnet_models_used += 1\n",
        "\n",
        "    else:\n",
        "        model[\"path\"] = {\n",
        "            \"unet\": k[\"path\"],\n",
        "            \"vae\": k[\"path\"],\n",
        "            \"tokenizer\": k[\"path\"],\n",
        "            \"encoder\": k[\"path\"],\n",
        "        }\n",
        "\n",
        "    all_models.append(model)\n",
        "\n",
        "\n",
        "def get_by_model_name(model_name):\n",
        "    for k in all_models:\n",
        "        if k[\"name\"] == model_name:\n",
        "            return k\n",
        "\n",
        "\n",
        "unet_models = [get_by_model_name(k) for k in unet_model_names]\n",
        "vae_model = get_by_model_name(vae_model_name)\n",
        "tokenizer_model = get_by_model_name(tokenizer_model_name)\n",
        "encoder_model = get_by_model_name(encoder_model_name)\n",
        "\n",
        "vae_subfolder = None if vae_model_name == \"mse\" else \"vae\"\n",
        "if vae_model[\"name\"] == \"ad\":\n",
        "    vae_model[\"path\"][\"vae\"] = \"ckpt/anything-v3-vae-swapped\"\n",
        "\n",
        "GampipeSD.init_unets([k[\"path\"][\"unet\"] for k in unet_models], unet_merge_ratio, [{\"revision\": k[\"branch\"]} for k in unet_models])\n",
        "GampipeSD.init_vae(vae_model[\"path\"][\"vae\"], vae_subfolder, revision=vae_model[\"branch\"])\n",
        "GampipeSD.init_tokenizer(tokenizer_model[\"path\"][\"tokenizer\"], revision=tokenizer_model[\"branch\"], subfolder=\"tokenizer\")\n",
        "GampipeSD.init_encoder(encoder_model[\"path\"][\"encoder\"], torch_dtype=torch.float16, revision=encoder_model[\"branch\"], subfolder=\"text_encoder\")\n",
        "\n",
        "GampipeSD.to_device()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Upload Autotagger Image { display-mode: \"form\" }\n",
        "\n",
        "deepbooru_image_path = upload_img(deepbooru_image_dir)\n"
      ],
      "metadata": {
        "id": "yJ8LjbDC7Ssf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Upload Init Image { display-mode: \"form\" }\n",
        "\n",
        "init_image_path = upload_img(init_image_dir)\n"
      ],
      "metadata": {
        "id": "Xy3NHzy-_jF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypllz_Kjrk2m"
      },
      "outputs": [],
      "source": [
        "# @title # Settings { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ## General Settings\n",
        "config = {}\n",
        "\n",
        "prompt = \"sks mori_calliope\"  # @param {type:\"string\"}\n",
        "negative_prompt = \"poo quality, bad quality\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "aspect_ratio = \"vertical\" #@param [\"vertical\", \"horizontal\", \"square\"]\n",
        "guidance_scale = 12  # @param {type:\"slider\", min:-50, max:50, step:1}\n",
        "steps = 50  # @param {type:\"slider\", min:1, max:150, step:1}\n",
        "seed = -1  # @param {type:\"integer\"}\n",
        "# @markdown ***\n",
        "\n",
        "number_of_images = 3  # @param {type:\"slider\", min:1, max:12, step:1}\n",
        "\n",
        "# @markdown ***\n",
        "# @markdown #### Danbooru autotagger\n",
        "use_auto_tagger = False #@param {type:\"boolean\"}\n",
        "max_tags = 16  # @param {type:\"slider\", min:1, max:50, step:1}\n",
        "confidence_thresh = 1  # @param {type:\"slider\", min:1, max:99, step:1}\n",
        "excluded_tags = \"censor, pubic, futa, penis\"  # @param {type:\"string\"}\n",
        "\n",
        "if use_auto_tagger:\n",
        "    try:\n",
        "        deepbooru_image_path\n",
        "    except:\n",
        "        raise Exception(\"No autotagger image was uploaded\")\n",
        "    \n",
        "    preds = deepbooru(str(deepbooru_image_path))\n",
        "    prompt = tags_to_prompt(prompt, preds, excluded_tags, max_tags, confidence_thresh / 100)\n",
        "\n",
        "# @markdown ***\n",
        "# @markdown ### img2img settings\n",
        "\n",
        "\n",
        "use_init_image = False #@param {type:\"boolean\"}\n",
        "init_image_strength = 18  # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "\n",
        "width = height = 512\n",
        "if aspect_ratio == \"vertical\":\n",
        "  height = 768\n",
        "elif aspect_ratio == \"horizontal\":\n",
        "  width = 768\n",
        "\n",
        "\n",
        "init_image = None\n",
        "mask_image = None\n",
        "if use_init_image:\n",
        "    try:\n",
        "        init_image_path\n",
        "    except:\n",
        "        raise Exception(\"No init image was uploaded\")\n",
        "    \n",
        "    init_image = load_init_image(init_image_path)\n",
        "\n",
        "    display.display(init_image)\n",
        "\n",
        "    init_image_strength = float(1 - init_image_strength / 100)\n",
        "    width = height = None\n",
        "else:\n",
        "    init_image_strength = None\n",
        "\n",
        "\n",
        "prompt = prompt.lower().strip()\n",
        "negative_prompt = negative_prompt.lower().strip()\n",
        "\n",
        "config[\"prompt\"] = prompt\n",
        "config[\"negative_prompt\"] = negative_prompt\n",
        "config[\"guidance_scale\"] = float(guidance_scale)\n",
        "config[\"init_image_strength\"] = init_image_strength\n",
        "config[\"seed\"] = seed\n",
        "config[\"n_iter\"] = number_of_images\n",
        "config[\"steps\"] = steps\n",
        "\n",
        "config[\"width\"] = width\n",
        "config[\"height\"] = height\n",
        "\n",
        "config_json = json.dumps(config, indent=2)\n",
        "\n",
        "with open(str(config_path), \"w\") as f:\n",
        "    f.write(config_json)\n",
        "\n",
        "print(get_printable_json_config(config_json))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U54_fUllIVm"
      },
      "source": [
        "### Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLtK1O9KYqOw"
      },
      "outputs": [],
      "source": [
        "# @title Generate { display-mode: \"form\" }\n",
        "# Read config\n",
        "\n",
        "# set shortcuts required by cross attention control code\n",
        "# device = GampipeSD.device\n",
        "# dtype = GampipeSD.torch_dtype\n",
        "\n",
        "# clip_tokenizer = GampipeSD.clip_tokenizer\n",
        "# clip_model = GampipeSD.clip_model\n",
        "# clip = clip_model.text_model\n",
        "# unet = GampipeSD.unet\n",
        "# vae = GampipeSD.vae\n",
        "# scheduler = GampipeSD.scheduler\n",
        "\n",
        "\n",
        "config = read_config()\n",
        "printable_config = get_printable_json_config(json.dumps(config, indent=2))\n",
        "\n",
        "print_config = \"<p>\"\n",
        "for line in printable_config.splitlines():\n",
        "    print_config += line + \"<br>\"\n",
        "print_config += \"</p>\"\n",
        "\n",
        "config_widget = widgets.HTML(\n",
        "    value=print_config,\n",
        "    placeholder=\"Config\",\n",
        ")\n",
        "\n",
        "\n",
        "# Get prompt variations\n",
        "prompts = parse_prompt(config[\"prompt\"])\n",
        "\n",
        "\n",
        "# Create outputs widgets to control order of outputs\n",
        "out = widgets.Output(layout=layouts[\"output\"])\n",
        "out1 = widgets.Output(layout=layouts[\"output\"])\n",
        "out2 = widgets.Output(layout=layouts[\"output\"])\n",
        "app = widgets.VBox([out, out1, out2])\n",
        "display.display(app)\n",
        "\n",
        "gb = widgets.GridBox([], layout=layouts[\"img_grid\"])\n",
        "with app.children[0]:\n",
        "    display.display(config_widget)\n",
        "\n",
        "with app.children[1]:\n",
        "    display.display(gb)\n",
        "\n",
        "# # Include button icons\n",
        "# with app.children[2]:\n",
        "#     display.display(\n",
        "#         display.HTML(\n",
        "#             \"\"\"<link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\"> \"\"\"\n",
        "#         )\n",
        "#     )\n",
        "\n",
        "\n",
        "# Generate\n",
        "images = []\n",
        "i = 0\n",
        "for prompt in prompts:\n",
        "    for iter in range(config[\"n_iter\"]):\n",
        "        # set seed\n",
        "        seed = config[\"seed\"] + iter\n",
        "\n",
        "        with app.children[2]:\n",
        "            img = GampipeSD.generate(\n",
        "                seed=seed,\n",
        "                prompt=prompt[0],\n",
        "                negative_prompt=config[\"negative_prompt\"],\n",
        "                guidance_scale=config[\"guidance_scale\"],\n",
        "                strength=config[\"init_image_strength\"],\n",
        "                image=init_image,\n",
        "                mask_image=mask_image,\n",
        "                width=config[\"width\"],\n",
        "                height=config[\"height\"],\n",
        "                num_inference_steps=config[\"steps\"],\n",
        "                scheduler_type=\"dpm\",\n",
        "            )[0]\n",
        "\n",
        "        compressed = pil_to_bytes(img, \"png\")\n",
        "        images.append(compressed)\n",
        "\n",
        "        label = generate_label(prompt, config, seed, iter)\n",
        "\n",
        "        # Create widgets\n",
        "        info = widgets.HBox(\n",
        "            [\n",
        "                widgets.HTML(\n",
        "                    value=label,\n",
        "                    placeholder=\"Label\",\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        image_widget = widgets.VBox(\n",
        "            [info, widgets.Image(value=compressed, layout=layouts[\"img\"])]\n",
        "        )\n",
        "\n",
        "        gb.children = (*gb.children, image_widget)\n",
        "\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3RKjTO1jo_R"
      },
      "source": [
        "# SwinIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pXogAPUkwj_"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF4Pob_vjv0I"
      },
      "outputs": [],
      "source": [
        "!rm -r SwinIR\n",
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o0KuEmLj2oC"
      },
      "outputs": [],
      "source": [
        "def is_img(fn):\n",
        "    ext = [\"png\", \"jpg\", \"jpeg\"]\n",
        "\n",
        "    for ext in ext:\n",
        "        if fn.endswith(f\".{ext}\"):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def get_images(path):\n",
        "    files = os.listdir(path)\n",
        "\n",
        "    for f in files:\n",
        "        if not is_img(f):\n",
        "            files.remove(f)\n",
        "    return files\n",
        "\n",
        "\n",
        "def force_make_dir(path):\n",
        "    if path.is_dir():\n",
        "        shutil.rmtree(path)\n",
        "    path.mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGcOGF91j4qw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import path as osp\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "result_root = pth(\"results\")\n",
        "upload = pth(\"SwinIR Upload\")\n",
        "swin_result = result_root / \"swinir_real_sr_x4_large\"\n",
        "\n",
        "for path in [result_root, upload, swin_result]:\n",
        "    force_make_dir(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lBB2TX4k2X2"
      },
      "source": [
        "## App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8FZUnTLlIVs"
      },
      "source": [
        "### Upscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QP7kQkSCkBT8"
      },
      "outputs": [],
      "source": [
        "#@title Upscale\n",
        "tiled = True #@param {type:\"boolean\"}\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "!rm -r $swin_result/*\n",
        "\n",
        "# SwinIR-Large\n",
        "if tiled:\n",
        "  !python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq \"$upload\" --scale 4 --large_model --tile 256\n",
        "else:\n",
        "  !python SwinIR/main_test_swinir.py --task real_sr --model_path experiments/pretrained_models/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN.pth --folder_lq \"$upload\" --scale 4 --large_model\n",
        "shutil.rmtree('results/SwinIR_large', ignore_errors=True)\n",
        "shutil.move('results/swinir_real_sr_x4_large', 'results/SwinIR_large')\n",
        "for path in sorted(glob.glob(os.path.join('results/SwinIR_large', '*.png'))):\n",
        "  img = cv.imread(path)\n",
        "  cv.imwrite(path, img, [cv.IMWRITE_PNG_COMPRESSION, 9])\n",
        "  # os.rename(path, path.replace('SwinIR.png', 'SwinIR_large.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uS-NvNhk0KrS",
        "Z3RKjTO1jo_R",
        "2pXogAPUkwj_"
      ],
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('env_mfct')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8a0b49fd0c4635c91c882b7e82e49057ce426a150a19cf02f92541aeeca7358"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}